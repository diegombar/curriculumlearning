{
    "batch_size": 32,
    "discount_factor": 0.99,
    "e_max": 1.0,
    "e_min": 0.01,
    "e_update_steps": 666666,
    "max_steps_per_episode": 500,
    "notes": "goal_reward = 1, exponential decay reward",
    "num_episodes": 4000,
    "replay_memory_size": 100000,
    "replay_start_size": 50000,
    "train_model_steps_period": 4,
    "update_target_net_rate_tau": 0.001
}