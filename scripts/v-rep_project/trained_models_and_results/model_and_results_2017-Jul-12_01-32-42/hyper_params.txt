{
    "_commit_hash": "3c086982c8fc4c58c766f1dbdf11872d0d2fdb04",
    "batch_size": 32,
    "discount_factor": 0.99,
    "e_max": 1.0,
    "e_min": 0.01,
    "e_tau": 240000.0,
    "joint_velocity": 0.3,
    "learning_rate": 1e-06,
    "load_model": false,
    "max_steps_per_episode": 500,
    "neurons_per_hidden_layer": 50,
    "notes": "back to positive rewards",
    "num_episodes": 3000,
    "num_hidden_layers": 2,
    "number_of_actions": 18,
    "number_of_joints": 6,
    "replay_memory_size": 500000,
    "replay_start_size": 50000,
    "rewards_decay_rate": 5.0,
    "rewards_normalizer": 0.1,
    "showGUI": true,
    "skip_training": false,
    "state_size": 6,
    "train_model_steps_period": 4,
    "update_target_net_rate_tau": 0.001
}