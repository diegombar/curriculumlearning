{
    "_commit_hash": "ab107c7ccd0c3c5c8c1cf1bf52fbc3e28c16655b",
    "batch_size": 32,
    "discount_factor": 0.99,
    "e_max": 1.0,
    "e_min": 0.01,
    "e_tau": 160000.0,
    "joint_velocity": 0.3,
    "learning_rate": 1e-06,
    "load_model": false,
    "max_steps_per_episode": 500,
    "neurons_per_hidden_layer": 50,
    "notes": "changed to negative rewards",
    "num_episodes": 2000,
    "num_hidden_layers": 2,
    "number_of_actions": 18,
    "number_of_joints": 6,
    "replay_memory_size": 500000,
    "replay_start_size": 50000,
    "rewards_decay_rate": 3,
    "rewards_normalizer": 0.1,
    "showGUI": true,
    "skip_training": false,
    "state_size": 6,
    "train_model_steps_period": 4,
    "update_target_net_rate_tau": 0.001
}